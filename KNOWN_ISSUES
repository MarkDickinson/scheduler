These are the current issues, and whether I consider them a bug or not.

Issue1 - Don't change the servers timezone (not a bug)
Issue2 - All job numbers are 000000 (not a bug)
Issue3 - Design decision for systemd (not a bug)
Issue4 - JS port 9002 not released when job scheduler killed if JS job started another
         tcpip process (only seen when the scheduler starts snort)

-------------------------------------------------------------------------------------------
                     Issue1 - Don't change the servers timezone
                                **  NOT A BUG **
-------------------------------------------------------------------------------------------
If the server timezone is changed the scheduled time for a job to be run does not detect the
timezone change until after the job next runs, at the time it then recalculates it's next
runtime. For example if you change a timezone offset by 12 hours every job will run for the
next execution only 12 hours out from when you would expect it to.
Future executions will be at the correct time.

This was found myself when I changed a server timezone from EST to NZ time. There have been
no user reported occurrences of this (probably changing the timezone is not a common practise).

While the server time had changed to NZ time jobs were still scheduled to run at EST time.
Stopping and starting the scheduler does not resolve the problem, nor does rebooting the server;
the jobs remained scheduled at EST time. This is because the active scheduler queue uses binary
timestamps taken at the initial scheduling time, so changing offsets by 12-13hrs will throw out
the job scheduling time by the same amount until the jobs next get rescheuled.

The aberation lasts only until a job is run. After each job is run it is rescheduled based on
the new timezone. 

I have no intention of trying to resolve this issue, most servers don't get their timezones
changed after they are installed. If they do it is a manual action on your system admins
part. There is nothing that can be coded in the job scheduler to resolve this, it does not
do anything silly like check to see if a timezone offset has been changed every 5 minutes or
so, that would be a waste of cycles for something that is unlikely to ever happen in the real world.

-------------------------------------------------------------------------------------------
                     Issue2 - All job numbers are 000000
                                **  NOT A BUG **
-------------------------------------------------------------------------------------------
This is just something I have needed needed to implement, and have in fact forgotten why
I created the field in the first place as jobs are keyed by jobname.

Just something to be aware of when you display job details, the field is expected to be 
all zeros.

-------------------------------------------------------------------------------------------
                       Issue3 - Design decision for systemd
                               **  NOT A BUG **
-------------------------------------------------------------------------------------------
The origional scheduler product, over a decade ago, had the server component go 'daemon' 
using the C system call daemon in order to background it and run as a true server task.
Unfortunately in the systemd world when a program goes daemon systemd loses track of it
and cleans it up, preventing the server from ever starting.

To resolve this the server component has had a source code change and no longer goes daemon,
allowing systemd to manage the startup, it does cause an issue for old SYSV systems and the
init.d rc startup script has been modified to use a messier nohup method as the server
can no longer cleanly go daemon, but that is a side issue.

The 'Design decision is that the service file uses a KillMode=process to limit it to
cleaning up only the bash process it uses to start the scheduler rather than the
default setting that would kill all child processes started by the service.

The reason for that is because systemd keeps track of everything started by the service
scheduled jobs that stop/start applications periodically (for backups, to sort out
memory hogs etc) are tracked as children of the scheduler by systemd... and in the
default KillMode would all be killed if a systemctl stop against the scheduler service
was issued.

For example I have a regular job to restart 'snort', and after a restart it becomes a
child of the job scheduler service instead of being free to live its own life. As a result
if a systemctl stop was issued against the job scheduler service using the default KillMode
the snort application would also be killed as part of the service stoppingi (along with 
anything regularly cycled by the scheduler to release memory such as mariadb and httpd).

[root@phoenix system]# systemctl status marks_job_scheduler
● marks_job_scheduler.service - Marks Job Scheduler
   Loaded: loaded (/usr/lib/systemd/system/marks_job_scheduler.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2019-07-10 11:25:19 NZST; 25min ago
     Docs: man:jobsched_daemon(1)
 Main PID: 13362 (bash)
    Tasks: 4 (limit: 3863)
   Memory: 62.6M
   CGroup: /system.slice/marks_job_scheduler.service
           ├─13362 /bin/bash -c cd /opt/dickinson/scheduler;/opt/dickinson/scheduler/bin/jobsched_daemon 9002 
           ├─13363 /opt/dickinson/scheduler/bin/jobsched_daemon 9002
           └─31485 /usr/local/bin/snort -D -A fast -b -d -i enp3s0 -u snort -g snort -c /etc/snort/snort.conf -l /var/log/snort -b

As the default KillMode would result in anything stopped/started by script by scheduler jobs
being killed when the service is stopped (suddenly disapearing applications and databases
are not ideal) the default KillMode simply cannot be used by this service.

Potentially an issue as unwanted child processes may be left hanging about by
this decision, but preferable to having applications that may be started by the
job scheduler service suddenly killed.
More potentially an issue as if the scheduler ../etc/stop_cmds file is ever manually
edited by a user that intoduces invalid syntax the jobsched_daemon process will not
be stopped by the service, so don't play with that file.

Note: this is a perfectly valid design solution, it is in fact the same solution used
      by the crond.service file, which also does not want child processes it may start
      killed off by a systemctl stop crond.

-------------------------------------------------------------------------------------------
              Issue4 - JS port 9002 not released when job scheduler killed
              if another tcpip process was started under scheduler control
                               **  POSSIBLE BUG **
  (I might update the scheduler to try to trap the kill signal one day and cleanly stop)
-------------------------------------------------------------------------------------------
Found in a situation where I stopped the job scheduler with a 'kill -9'.
The 'snort' process which does not use port 9002 but which had been started by the scheduler
took ownership of the port and kept it open.

[root@phoenix init.d]# netstat -anp | grep 9002
tcp        2      0 192.168.1.187:9002      0.0.0.0:*               LISTEN      3331576/snort  

That should not have happened or been permitted by the operating system.
This may be specific to "snort" as it monitors activity on ports.

This does not happen when the scheduler is shutdown on a controlled fashion with "sched shutdown"
(note: sched shutdown is also issues by the supplied service file).

RESOLUTION: avoid using 'kill' to stop the scheduler, always try to shut it down properly.

